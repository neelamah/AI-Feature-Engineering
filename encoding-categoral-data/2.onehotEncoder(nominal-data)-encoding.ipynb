{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a83322",
   "metadata": {},
   "outputs": [],
   "source": [
    "OneHotEncoder is aply only on nominal data (which doest have rank) and need to drop first column  to handle multicollinearity\n",
    "\n",
    "ðŸ”¹ When to NOT use drop='first'\n",
    "\n",
    "Tree-based models like Decision Tree, Random Forest, XGBoost\n",
    "â†’ They donâ€™t care about multicollinearity, so you can keep all columns.\n",
    "\n",
    "Only important for linear models, regression, or logistic regression.\n",
    "\n",
    "\n",
    "*Multicollinearity occurs when two or more independent (feature) variables are highly correlated with each other.\n",
    "\n",
    "In other words, one feature can be predicted from the others.\n",
    "\n",
    "This causes redundancy in the dataset.\n",
    "\n",
    "like :- \n",
    "Ht Wt\tBMI\n",
    "170\t70\t24.2\n",
    "180\t80\t24.7\n",
    "160\t60\t23.4\n",
    "\n",
    "BMI â‰ˆ Weight / (Height^2)\n",
    "\n",
    "So BMI is highly correlated with Height and Weight\n",
    "\n",
    "If you include all three as independent variables, the model will have multicollinearity. so we can remove one .\n",
    "\n",
    "note\n",
    "drop='first' is needed for linear/logistic regression to avoid multicollinearity, optional for tree models(Decision Tree\n",
    "Random Forest\n",
    "Gradient Boosting (XGBoost, LightGBM)) because Trees donâ€™t care about multicollinearity because they donâ€™t compute coefficients like linear regression does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7975909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age   review education purchased  gender_Male\n",
      "0    30  Average    School        No          0.0\n",
      "1    68     Poor        UG        No          0.0\n",
      "2    70     Good        PG        No          0.0\n",
      "3    72     Good        PG        No          0.0\n",
      "4    16  Average        UG        No          0.0\n",
      "5    31  Average    School       Yes          0.0\n",
      "6    18     Good    School        No          1.0\n",
      "7    60     Poor    School       Yes          0.0\n",
      "8    65  Average        UG        No          0.0\n",
      "9    74     Good        UG       Yes          1.0\n",
      "10   98     Good        UG       Yes          0.0\n",
      "11   74     Good        UG       Yes          1.0\n",
      "12   51     Poor    School        No          1.0\n",
      "13   57  Average    School        No          0.0\n",
      "14   15     Poor        PG       Yes          1.0\n",
      "15   75     Poor        UG        No          1.0\n",
      "16   59     Poor        UG       Yes          1.0\n",
      "17   22     Poor        UG       Yes          0.0\n",
      "18   19     Good    School        No          1.0\n",
      "19   97     Poor        PG       Yes          1.0\n",
      "20   57  Average    School       Yes          0.0\n",
      "21   32  Average        PG        No          1.0\n",
      "22   18     Poor        PG       Yes          0.0\n",
      "23   96     Good    School        No          0.0\n",
      "24   16  Average        PG       Yes          0.0\n",
      "25   57     Good    School        No          0.0\n",
      "26   53     Poor        PG        No          0.0\n",
      "27   69     Poor        PG        No          0.0\n",
      "28   48     Poor    School        No          1.0\n",
      "29   83  Average        UG       Yes          0.0\n",
      "30   73  Average        UG        No          1.0\n",
      "31   22     Poor    School       Yes          0.0\n",
      "32   92  Average        UG       Yes          1.0\n",
      "33   89     Good        PG       Yes          0.0\n",
      "34   86  Average    School        No          1.0\n",
      "35   74     Poor    School       Yes          1.0\n",
      "36   34     Good        UG       Yes          0.0\n",
      "37   94  Average        PG       Yes          1.0\n",
      "38   45     Good    School        No          0.0\n",
      "39   76     Poor        PG        No          1.0\n",
      "40   39     Good    School        No          1.0\n",
      "41   23     Good        PG       Yes          1.0\n",
      "42   30     Good        PG       Yes          0.0\n",
      "43   27     Poor        PG        No          1.0\n",
      "44   77  Average        UG        No          0.0\n",
      "45   61     Poor        PG       Yes          1.0\n",
      "46   64     Poor        PG        No          0.0\n",
      "47   38     Good        PG       Yes          0.0\n",
      "48   39     Good        UG       Yes          0.0\n",
      "49   25     Good        UG        No          0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Sample dataset\n",
    "df = pd.read_csv(\"data/customer.csv\")\n",
    "\n",
    "# Select nominal column to encode\n",
    "nominal_cols = ['gender']\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "ohe = OneHotEncoder(drop='first', sparse_output=False)  # drop='first' avoids dummy variable trap\n",
    "\n",
    "# Fit and transform\n",
    "gender_encoded = ohe.fit_transform(df[nominal_cols])\n",
    "\n",
    "# Convert to DataFrame for readability\n",
    "gender_encoded_df = pd.DataFrame(gender_encoded, columns=ohe.get_feature_names_out(nominal_cols))\n",
    "\n",
    "# Concatenate with original dataframe (without original 'gender' column)\n",
    "df_final = pd.concat([df.drop(columns=nominal_cols), gender_encoded_df], axis=1)\n",
    "\n",
    "print(df_final)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
